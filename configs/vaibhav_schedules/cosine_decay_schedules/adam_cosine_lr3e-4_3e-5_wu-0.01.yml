{
"optimizer": {
    "type": "Adam",
    "params": {
      "lr": 3.0e-4,
      "betas": [0.9, 0.95],
      "eps": 1.0e-8,
    }
  },
  "min_lr": 3.0e-5,
  "lr-decay-style": "cosine",
  "warmup": 0.01,
  "constant_iters_percent" : 0.85, # This argument does not affect lr, its only required to save the model(HACKY solution)
}
